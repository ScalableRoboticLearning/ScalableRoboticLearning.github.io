## Overview
In recent years, both the computer vision and the machine learning communities have shown an increasing interest in the specific challenges of robotic perception and planning. This field features a high demand for feasible training procedures, strong generalization capabilities, fast runtime, interpretable models and robustness. However, current state-of-the-art approaches can still not meet all these requirements, which is why perception is often seen as the bottleneck for robotic manipulation.

This workshop serves as a platform to connect communities and encourage them to find feasible solutions that bridge the gap between stand-alone perception and robotic related tasks such as motion or assembly planning, visual servoing and grasping. A main topic is how sensing, manipulation and planning can be combined to yield mutual benefits. We also search for scalable learning-based approaches that require little supervision and examine them on their benefits and limitations. Are end-to-end learning approaches really the right way to go or are modular pipelines still preferable due to better introspection? What is necessary to address the needs of end-user applications in terms of robustness, runtime, cost, maintainability and fail-safety? 

## Invited Speakers
* [__Kai Arras__](https://www.bosch.com/de/forschung/know-how/forscher/dr-kai-oliver-arras/), Bosch Robotics Research Program (__confirmed__)
* [__Michael Beetz__](http://ai.uni-bremen.de/team/michael_beetz), University Bremen (requested)
* [__Jeanette Bohg__](https://am.is.tuebingen.mpg.de/person/jbohg), Stanford University (tentative)
* [__Renaud Detry__](https://www-robotics.jpl.nasa.gov/people/Renaud_Detry/), NASA JPL (__confirmed__)
* [__Dieter Fox__](https://homes.cs.washington.edu/~fox/), University of Washington, as well as NVIDIA AI Robotics Research Lab (__confirmed__)
* [__Maxim Likhachev__](http://www.cs.cmu.edu/~maxim/), Robotics Institute Carnegie Mellon University (__confirmed__)
* [__Peter Pastor__](https://www.linkedin.com/in/peter-pastor-sampedro-824aa584/), X (tentative)
* [__Maximo Roa__](https://rmc.dlr.de/rm/de/staff/maximo.roa/), RoboCeption GmbH and DLR (__confirmed__)
* [__Siddhartha Srinivasa__](https://goodrobot.ai/), University of Washington and Director of Robotics at Amazon (__confirmed__) 

## Call for Papers
We solicit 2-4 page extended abstracts (following RSS style guidelines). The submissions can include: __late-breaking results__, __under review material__, __archived__, or __previously accepted work__. We strongly encourage the preparation of live demos or videos accompanying the submission.

* Reducing the setup time through automatized training procedures
  * What do we gain / sacrifice with the current methods that require less supervision?
  * Transfer learning, learning in simulation, automatic labeling, reinforcement learning
* How can the interaction between sensing, manipulation and planning yield mutual benefits?
  * e.g. Extracting semantic information from visual/tactile data for improved execution planning
* Scalable approaches for grasping novel objects and for generalizing functional grasps
* As end-to-end approaches gain traction, which benefits and limitations do they possess compared to modular pipelines?
  * How can we achieve introspection in end-to-end methods?
  * Are commonly used subtask metrics in modular approaches suitable indicators for execution success?
* Which possibilities for automatic recovery exist to create failure proof systems?
* Addressing the needs of end-user applications in terms of robustness, runtime, cost, maintainability, etc.

Submitted papers will be reviewed by the organizers and invited reviewers. Accepted contributions will be presented as posters or within the Demo/Video Talk format. Selected papers are further featured as spotlight talks. All accepted contributions and posters will be posted on the workshop website upon author approval

## SCHEDULE
| Time  | Topic |
| ------------- | ------------- |
| __8:30 - 8:45__ | Introductory Remarks  |
| __8:45 - 9:15__ | __Invited talk__: to be defined |
| __9:30 - 10:00__ | __Invited talk__: to be defined |
| __10:15 - 10:30__ | __Poster spotlights 1__ |
| __10:30 - 11:00__ | __Coffee Break + Posters__ |
| __11:00 - 11:30__ | __Invited talk__: to be defined |
| __11:45 - 1:30__ | __Lunch Break__ |
| __1:30 - 2:00__ | __Invited talk__: to be defined |
| __2:15 - 2:30__ | __Poster spotlights 2__ |
| __2:30 - 3:00__ | __Coffee Break + Posters__ |
| __3:00 - 3:30__ | __Invited talk__: to be defined |
| __3:45 - 4:00__ | __Demo/video talks__ |
| __4:00 - 4:30__ | __Invited talk__: to be defined |
| __4:45 - 5:15__ | __Discussion with participation of the audience and experts__ |

## Organizing Committee
* Maxiimilian Durner <maximilian.durner@dlr.de>
* Martin Sundermeyer <Martin.sundermeyer@dlr.de>
* Zoltan Marton <zoltan.marton@dlr.de>
* EnYen Puang <en.puang@dlr.de> 
* Rudolph Triebel <rudolph.triebel@dlr.de>

## Contact
Should you have any questions, please do not hesitate to contact the organizers.
